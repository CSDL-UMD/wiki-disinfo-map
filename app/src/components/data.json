[
   {
      "id1": "Open the Knowledge Journalism Award",
      "id2": "Disinformation on Wikimedia projects often appears in areas in which there are content voids. For this reason, working on filling knowledge gaps is one way Wikimedia can work to increase trustworthy information on the projects. The Wikimedia Foundation has launched the Open the Knowledge Journalism Awards, which recognizes the essential role journalists play in creating well-researched articles that volunteer editors can use as source materials to develop content on Wikipedia and other Wikimedia projects. The award is focused on articles by African journalists increasing knowledge about the African continent.[10]",
      "id3": "English",
      "id4": "NA",
      "id5": "Middle East & North Africa / Sub-Saharan Africa",
      "id6": "2023",
      "id7": "Wikimedia Foundation",
      "id": "id1"
   },
   {
      "id1": "1 Lib 1 Ref (#1Lib1Ref)",
      "id2": "Twice per year, #1Lib1Ref—an abbreviation for “one librarian, one reference”—calls on librarians around the world, and anyone who has a passion for free knowledge, to add missing references to articles on Wikipedia. By increasing the use of reliable sources, the project improves the accuracy of the information.[1]",
      "id3": "Indonesian, Malay, Bikol, German, English, Esperanto, Dutch, Sundanese, Vietnamese, Turkish, Catalan, Danish, Spanish, Basque, French, Galician, Italian, Latvian, Hungarian, Norwegian, Polish, Portuguese, Brazilian Portuguese, Romanian, Slovenian, Suomi, Swedish, Czech, Greek, Belarusian, Macedonian, Russian, Serbian, Ukrainian, Hebrew, Urdu, Arabic, Sindhi, Farsi, Hindi, Bangla, Tamil, Malayalam, Thai, Burmese, Chinese, and Japanese",
      "id4": "Multiple",
      "id5": "Global",
      "id6": "2016 (according to Talk page)",
      "id7": "Wikimedia Foundation",
      "id": "id2"
   },
   {
      "id1": "Knowledge integrity, Wikimedia Research",
      "id2": "The Wikimedia Foundation’s Research team published a set of white papers that outline plans and priorities for the next 5 years. These white papers, which were developed collaboratively by all members of the team, reflect our thinking about the kind of research necessary to further the 2030 Wikimedia Strategic Direction of Knowledge Equity and Knowledge as a Service.[6]",
      "id3": "English",
      "id4": "NA",
      "id5": "Global",
      "id6": "2019-",
      "id7": "Wikimedia Foundation",
      "id": "id3"
   },
   {
      "id1": "Machine Learning based service to predict reverts on Wikipedia, Wikimedia Research",
      "id2": "Models to detect revisions that might be reverted, independently if they were made in good faith or with the intention of creating damage, to help patrollers quickly identify potential problems, prioritize the work, and revert damaging edits when needed.",
      "id3": "NA",
      "id4": "NA",
      "id5": "Global",
      "id6": "2022",
      "id7": "Wikimedia Foundation",
      "id": "id4"
   },
   {
      "id1": "ORES",
      "id2": "ORES is a web service and API that provides machine learning as a service for Wikimedia projects maintained by the Machine Learning team. The system is designed to help automate critical wiki-work—for example, vandalism detection and removal.[11]",
      "id3": "Multiple",
      "id4": "NA",
      "id5": "Global",
      "id6": "2016",
      "id7": "Wikimedia Foundation",
      "id": "id5"
   },
   {
      "id1": "Reading Wikipedia in the classroom",
      "id2": "Reading Wikipedia in the Classroom is Wikimedia Foundation’s teacher training program. By leveraging Wikipedia as a pedagogical tool, it helps educators and students develop vital media and information literacy skills for the 21st century.[13]",
      "id3": "English, Arabic, French, Spanish, Tagalog, Adapted English (Nigeria), Yoruba, Indonesian, Aymara, Guaranì, Quechua, Catalan, Dagbani",
      "id4": "NA",
      "id5": "Global",
      "id6": "2021",
      "id7": "Wikimedia Foundation",
      "id": "id6"
   },
   {
      "id1": "Reliable sources noticeboard",
      "id2": "This is a noticeboard in which the community can discuss reliable sources. Guidelines for the use of reliable sources on En.WP can be found at Wikipedia:Reliable sources and Wikipedia:Reliable sources/Perennial sources.",
      "id3": "English",
      "id4": "NA",
      "id5": "Global",
      "id6": "2007",
      "id7": "NA",
      "id": "id7"
   },
   {
      "id1": "Wikipedia:WikiProject Climate change",
      "id2": "WikiProject Climate change is a collaborative effort to improve Wikipedia articles related to climate change. The WikiProject covers topics related to the causes of climatic change, the effects of climate change, and how society responds in terms of adaptation, mitigation and social and political change.[22]",
      "id3": "English, German, Spanish, French, Polish, Swedish, Vietnamese, Czech",
      "id4": "NA",
      "id5": "Global",
      "id6": "2010",
      "id7": "NA",
      "id": "id8"
   },
   {
      "id1": "Wikipedia:WikiProject COVID-19",
      "id2": "This is the WikiProject related to Wikipedia coverage of COVID-19. It consolidates and coordinates community efforts to create trustworthy information on the pandemic. It was developed in part also through a partnership with WHO.",
      "id3": "English, Urdu, Chinese, Korean, Russian, Spanish, Italian, Czech, Arabic, Shindi, Greek, Malay, Croatian, Dutch, Slovak, Finnish, Turkish, Marathi, Bangla, Punjabi, Telugu, Malayalam, Thai",
      "id4": "United States",
      "id5": "Global",
      "id6": "2020",
      "id7": "NA",
      "id": "id9"
   },
   {
      "id1": "WikiFactCheckers training",
      "id2": "This WikiCred project trains media professionals how to use Wikipedia, Wikidata, and WikiCommons.[18]",
      "id3": "English",
      "id4": "Nigeria",
      "id5": "Sub-Saharan Africa",
      "id6": "2023",
      "id7": "WikiCred, Code for Africa",
      "id": "id10"
   },
   {
      "id1": "¡Que no te pille la tecnología! Personas Mayores Informadas / Don't let technology catch you! Senior Citizens Informed",
      "id2": "This video was created as part of a campaign to empower the senior population to avoid disinformation when using the internet. Participants were volunteer attendees of the workshop \"Senior people and digital environments: tools for integration\", organized by Wikimedia Chile, Google Chile, and the Quilicura municipality in Santiago, who shared their own experiences on how they use online information.",
      "id3": "Spanish",
      "id4": "Chile",
      "id5": "Latin America & Caribbean",
      "id6": "2022",
      "id7": "Wikimedia Chile",
      "id": "id11"
   },
   {
      "id1": "Completude, consistência e correção em bases de dados digitais sobre mortos e desaparecidos políticos na ditadura civil-militar brasileira / Completeness, consistency, and correction in digital databases about victims and political desaparecidos during the Brazilian civic-military dictatorship",
      "id2": "This project is a research focused on improving content on those who were killed or disappeared during the military dictatorship in Brazil (1964-1985). In the context in which the federal government was shutting down websites with official content on human rights violations during the military regime in Brazil, Wiki Movimento Brasil and partners focused on bringing all this information into Wikidata and Wikipedia.",
      "id3": "Brazilian Portuguese",
      "id4": "Brazil",
      "id5": "Latin America & Caribbean",
      "id6": "2021",
      "id7": "Wiki Movimento Brasil",
      "id": "id12"
   },
   {
      "id1": "Introdução ao Jornalismo Científico / Introduction to Scientific Journalism",
      "id2": "This project relied on a partnership with a research lab, NeuroMat, and is a resource for young professionals to specialize in science journalism. Modules 3 and 6 are focused on how misinformation is spread in Brazil.",
      "id3": "Brazilian Portuguese",
      "id4": "Brazil",
      "id5": "Latin America & Caribbean",
      "id6": "2017",
      "id7": "Wiki Movimento Brasil",
      "id": "id13"
   },
   {
      "id1": "WikiCon Brazil",
      "id2": "The theme of the 2022 WikiCon Brazil was disinformation. This theme was developed through trainings, events, and presentations.",
      "id3": "Brazilian Portuguese",
      "id4": "Brazil",
      "id5": "Latin America & Caribbean",
      "id6": "2022",
      "id7": "Wiki Movimento Brasil",
      "id": "id14"
   },
   {
      "id1": "Wikidata Lab XIV, Modelagem com estruturação intencional / Wikidata Lab XIV, Modeling with intentional structuring",
      "id2": "This was a training on how to share resources and capabilities for the integration of Wikidata with other Wikimedia projects, especially Wikipedia.[17]",
      "id3": "Brazilian Portuguese",
      "id4": "Brazil",
      "id5": "Latin America & Caribbean",
      "id6": "2019",
      "id7": "Wiki Movimento Brasil",
      "id": "id15"
   },
   {
      "id1": "Wikipédia contra a ignorância racional / Wikipedia against rational ignorance",
      "id2": "This is a research paper on Wikipedia against \"rational ignorance\". João Alexandre Peschanski led this project as an educator before becoming Executive Director of Wiki Movement Brazil User Group (Grupo de Usuários Wiki Movimento Brasil), and it is framed around a specific behavioral dimension of misinformation in electoral politics. A summary is available on this Wikimedia blog post (with a link to a more substantial research paper), and it has evolved as a Wikidata-integrated system for improving content on elections in Brazil.",
      "id3": "Brazilian Portuguese",
      "id4": "Brazil",
      "id5": "Latin America & Caribbean",
      "id6": "2016",
      "id7": "Wiki Movimento Brasil",
      "id": "id16"
   },
   {
      "id1": "Wikipédia:Fontes confiáveis/Central de confiabilidade / Wikipedia:Reliable sources/Trust Center",
      "id2": "This is a page created to centralize discussions related to the sources used in articles which lists sources editors should avoid using in the project, many of which have been associated with disinformation campaigns. It is similar to lists of unreliable sources that exist for other language Wikipedias.[20]",
      "id3": "Brazilian Portuguese",
      "id4": "Brazil",
      "id5": "Latin America & Caribbean",
      "id6": "2022",
      "id7": "Wiki Movimento Brasil",
      "id": "id17"
   },
   {
      "id1": "CTRL-F",
      "id2": "Wikimedia Chile, Together with CIVIX, CIPER Chile Journalistic Research Center, and Fast Check organizes the CTRL-F program. A training program for students to teach them verification and media literacy techniques.",
      "id3": "Spanish",
      "id4": "Chile",
      "id5": "Latin America & Caribbean",
      "id6": "2023",
      "id7": "Wikimedia Chile",
      "id": "id18"
   },
   {
      "id1": "Unreliable guidelines - Reliable sources and marginalized communities in French, English, and Spanish Wikipedias",
      "id2": "This is a report of the research project Reading Together: Reliability and Multilingual Global Communities on reliable sources and marginalized communities on Wikipedia.",
      "id3": "English",
      "id4": "Canada, Peru, United States",
      "id5": "North America / Latin America & Caribbean",
      "id6": "2021",
      "id7": "Art+Feminism, WikiCred",
      "id": "id19"
   },
   {
      "id1": "Unreliable/Predatory Source Detector (UPSD)",
      "id2": "The Unreliable/Predatory Source Detector (UPSD), is a user script that identifies various unreliable and potentially unreliable sources.[15]",
      "id3": "English",
      "id4": "NA",
      "id5": "North America",
      "id6": "2020",
      "id7": "NA",
      "id": "id20"
   },
   {
      "id1": "ARTT (Analysis and Response Toolkit for Trust)",
      "id2": "This page centralizes information about reliable sources for new page reviewers to use when they review new articles. It is intended as a supplement to the reliable sources noticeboard and List of Perennial Sources, to help page reviewers unfamiliar with a given subject assess notability and neutrality of an article.[9]",
      "id3": "English",
      "id4": "United States",
      "id5": "North America",
      "id6": "2021",
      "id7": "National Science Foundation’s Convergence Accelerator, Hacks/Hackers, and the Paul G. Allen School of Computer Science & Engineering, University of Washington.For more information, please read footnote [1].",
      "id": "id21"
   },
   {
      "id1": "Cite Unseen",
      "id2": "Cite Unseen is a user script that adds categorical icons to Wikipedia citations, such as whether the citation counts as news, opinion, blog, state-run media, a published book, among others. These categorical icons provide readers and editors with a quick initial evaluation of citations at a glance. This helps guide users on the nature and reliability of sources, and to help identify sources that may potentially be problematic or should be used with caution.[3]",
      "id3": "English",
      "id4": "United States",
      "id5": "North America",
      "id6": "2019",
      "id7": "NA",
      "id": "id22"
   },
   {
      "id1": "Special:AbuseFilter891",
      "id2": "This is a filter that detects predatory publishers and flags them for editors.",
      "id3": "English",
      "id4": "United States",
      "id5": "North America",
      "id6": "2017",
      "id7": "NA",
      "id": "id23"
   },
   {
      "id1": "User:JL-Bot/DOI",
      "id2": "DOIs are unique identifiers for academic articles. This bot checks those DOIs that are issued by Crossref and can show who is the person associated with the DOI.",
      "id3": "English",
      "id4": "United States",
      "id5": "North America",
      "id6": "2007",
      "id7": "NA",
      "id": "id24"
   },
   {
      "id1": "Wikipedia:WikiProject COVID-19/SureWeCan COVID19 Task Force",
      "id2": "This task force project focuses on Wikipedia editing and writing to share simple, factual information on the coronavirus pandemic in New York City with the goal of explaining the seriousness of the pandemic.[23]",
      "id3": "English, Spanish, Chinese, Russian, Italian, Haitian Creole, Korean, French, Tagalog, Polish, Yiddish, Japanese, Hindi, Hebrew, Swahili, Malagasy, Yoruba, German, Portuguese, Arabic, Hungarian, Bengali, Greek",
      "id4": "United States",
      "id5": "North America",
      "id6": "2021",
      "id7": "Sure We Can",
      "id": "id25"
   },
   {
      "id1": "Wikipedia SWASTHA",
      "id2": "Wikipedia SWASTHA is an innovative, collaborative platform uniting multilingual editors from various Wikipedia communities to exchange best practices and jointly edit healthcare pages. Collaborating with diverse government agencies, the United Nations, and the World Health Organization, SWASTHA focuses on enhancing healthcare awareness in local communities by providing accessible, multilingual health information on Wikipedia. Recognized by prominent media outlets for its impactful work, SWASTHA highlights the ethical dissemination of medical information in local languages to empower individuals with limited access to healthcare resources. We invite organizations to join our mission and harness the power of Wikipedia to create a lasting, positive change in global healthcare.",
      "id3": "English, Urdu, Hindi, Bengali, Marathi, Telugu, Tamil, Gujarati, Kannada, Oddia, Malayalam, Punjabi, Bhojpuri, Maithili, and Nepali.",
      "id4": "NA",
      "id5": "East, Southeast Asia, & Pacific",
      "id6": "2020",
      "id7": "NA",
      "id": "id26"
   },
   {
      "id1": "HRVVMC Wikipedia Edit-a-thons",
      "id2": "The Human Rights Violations Victims’ Memorial Commission (HRVVMC), is a government agency tasked with documenting the human rights violations that occurred during the dictator’s regime and to establish a museum and a roll of victims. WikiSocPH worked with HRVVMC to help design training modules to train volunteers on how to edit Wikipedia articles related to the Marcos family and their regime. The Commission has conducted Wikipedia edit-a-thons to commemorate the initial declaration of martial law in 1972 and the Revolution in 1986 that ended the dictatorship.",
      "id3": "English",
      "id4": "Philippines",
      "id5": "East, Southeast Asia, & Pacific",
      "id6": "2020-2022",
      "id7": "WikiSocPH",
      "id": "id27"
   },
   {
      "id1": "Wikipedian in Residence at Bantayog ng mga Bayani",
      "id2": "The Bantayog ng mga Bayani is a foundation that maintains a memorial, museum, and library dedicated to remembering and honoring the heroes, martyrs, and victims of the Ferdinand Marcos dictatorship. WikiSocPH partnered with the Bantayog who hired a Wikimedian in Residence (WiR), to help digitize the Bantayog’s library, to improve Wikipedia’s coverage of articles related to the Ferdinand Marcos regime, and to organize Wikimedia events and workshops to the Bantayog’s visitors, researchers, and supporters.",
      "id3": "English",
      "id4": "Philippines",
      "id5": "East, Southeast Asia, & Pacific",
      "id6": "2018",
      "id7": "WikiSocPH",
      "id": "id28"
   },
   {
      "id1": "PSS 9",
      "id2": "PSS 9 is an intelligent software agent-administrator (a bot with administrative rights) on the Bulgarian Wikipedia, which employs artificial intelligence to identify and actively counter vandalism, including the spread of mis- and disinformation.[12]",
      "id3": "Bulgarian",
      "id4": "Bulgaria",
      "id5": "Central & Eastern Europe / Central Asia",
      "id6": "2017",
      "id7": "NA",
      "id": "id29"
   },
   {
      "id1": "Уикипедия:Патрульори/СФИН / Wikipedia:Patrollers/SFIN",
      "id2": "This is a filter maintained by the community of editors preventing the use of unreliable sources in the main space, and also in the incubator, by users who are not members of the \"autopatrolled\" group. When such a user tries to enter a link to a source in the list, the link is detected by the abuse filter that pulls data from the list and the edit is rejected.",
      "id3": "Bulgarian",
      "id4": "Bulgaria",
      "id5": "Central & Eastern Europe / Central Asia",
      "id6": "2016 (for the abuse filter); 2019 (adopted and enforced as a policy)",
      "id7": "NA",
      "id": "id30"
   },
   {
      "id1": "Croatian Wikipedia Disinformation Assessment",
      "id2": "This report evaluates a case of long-term systemic disinformation and project capture on the Croatian-language Wikipedia. The report was produced by an external expert, who conducted a thorough analysis of the content and community dynamics on the Croatian language Wikipedia. It revealed a widespread pattern of manipulative behavior and abuse of power by an ideologically aligned group of admins and volunteer editors. The views and opinions expressed in this report are those of the author and do not necessarily reflect the official policy or position of the Wikimedia Foundation.",
      "id3": "English",
      "id4": "NA",
      "id5": "Central & Eastern Europe / Central Asia",
      "id6": "2021",
      "id7": "Wikimedia Foundation",
      "id": "id31"
   },
   {
      "id1": "Wikipedia:Nierzetelne źródła / Wikipedia:Not reliable sources",
      "id2": "This is an editorial recommendation including a list of unreliable sources that should not be used by Polish Wikipedia editors, with an explanation of how these are selected and why.",
      "id3": "Polish",
      "id4": "Poland",
      "id5": "Central & Eastern Europe / Central Asia",
      "id6": "2022",
      "id7": "NA",
      "id": "id32"
   },
   {
      "id1": "Project: Patrolling/Monitoring vandalism (Wikipedia Ukrainian)",
      "id2": "This project is no longer active. It was a WikiProject to check all edits that were made by anonymous users. It helped prevent vandalism from remaining in articles for a long time. The project kept a patrol log of anonymous edits according to this filter. The project was supported by Wikimedia Ukraine, but not maintained by Wikimedia Ukraine. It was maintained by individual dedicated editors.",
      "id3": "Ukrainian",
      "id4": "Ukraine",
      "id5": "Central & Eastern Europe / Central Asia",
      "id6": "2020 (archived)",
      "id7": "Wikimedia Ukraine",
      "id": "id33"
   },
   {
      "id1": "Віківишколи/Тренінг для журналістів 19 травня 2019 / Wikivishkoli/Training for journalists 19 May 2019",
      "id2": "This is a master class on \"How to enter journalism into Wikipedia\" that was held in Kyiv in 2019, and organized by Wikimedia Ukraine together with the Institute for the Development of the Regional Press. The event was part of the Investigative Journalism Month held on Ukrainian Wikipedia in June-July.",
      "id3": "Ukrainian",
      "id4": "Ukraine",
      "id5": "Central & Eastern Europe / Central Asia",
      "id6": "2019",
      "id7": "Wikimedia Ukraine",
      "id": "id34"
   },
   {
      "id1": "Вікіпедія:Авторитетні джерела / Wikipedia: Authoritative sources",
      "id2": "This is a blog post explaining filter/list of untrustworthy sources that would flag them as untrustworthy for editors to use.",
      "id3": "Ukrainian",
      "id4": "Ukraine",
      "id5": "Central & Eastern Europe / Central Asia",
      "id6": "2020",
      "id7": "Wikimedia Ukraine",
      "id": "id35"
   },
   {
      "id1": "ГО «Вікімедіа Україна» попереджає: користуючись Вікіпедією, не платіть шахраям! / NGO \"Wikimedia Ukraine\" warns: When using Wikipedia, do not pay fraudsters!",
      "id2": "This is a blog post explaining how Wikipedia works and warning users against fraud and paid editing.",
      "id3": "Ukrainian",
      "id4": "Ukraine",
      "id5": "Central & Eastern Europe / Central Asia",
      "id6": "2020",
      "id7": "Wikimedia Ukraine",
      "id": "id36"
   },
   {
      "id1": "Як перевіряти інформацію: поради з фактчекінгу від Vox Check / How to check information: Fact-checking tips from Vox Check",
      "id2": "This is the abstract of a training on disinformation held by Wikimedia Ukraine in collaboration with Vox Check in 2021.",
      "id3": "Ukrainian",
      "id4": "Ukraine",
      "id5": "Central & Eastern Europe / Central Asia",
      "id6": "2021",
      "id7": "Wikimedia Ukraine",
      "id": "id37"
   },
   {
      "id1": "Як читати новини критично? and Експерти та експертність у медіа / How to read news critically? and Experts and expertise in the media",
      "id2": "This is the abstract of two training on disinformation and media literacy which were held by Wikimedia Ukraine in collaboration with Media Detector in 2020.",
      "id3": "Ukrainian",
      "id4": "Ukraine",
      "id5": "Central & Eastern Europe / Central Asia",
      "id6": "2020",
      "id7": "Wikimedia Ukraine",
      "id": "id38"
   },
   {
      "id1": "Decálogos para la lucha contra la desinformación en Wikipedia / Decalogues for the fight against disinformation on Wikipedia",
      "id2": "This is a training on misinformation and access to knowledge, in collaboration with Medialab-Prado. The event touched upon knowledge and strategies to fight disinformation on Wikipedia. It was directed to journalists, people who are dedicated to scientific research, activists, and Wikimedians.",
      "id3": "Spanish",
      "id4": "Spain",
      "id5": "Northern & Western Europe",
      "id6": "2020",
      "id7": "Wikimedia España",
      "id": "id39"
   },
   {
      "id1": "I Encuentro sobre lucha contra la desinformación en Wikipedia / 1st Meeting on the struggle against disinformation on Wikipedia",
      "id2": "This is a roundtable discussion with experts on the topic of disinformation on Wikipedia, organized by Wikimedia España in 2020.",
      "id3": "Spanish",
      "id4": "Spain",
      "id5": "Northern & Western Europe",
      "id6": "2020",
      "id7": "Wikimedia España",
      "id": "id40"
   },
   {
      "id1": "Laboratorio Wikimedia de verificación de datos / Wikimedia workshop on data verification",
      "id2": "This is a training called Wikimedia fact-checking lab: learning and collaboration around Wikimedia projects whose goal is to investigate information and data verification to defend Wikipedia from misinformation.",
      "id3": "Spanish",
      "id4": "Spain",
      "id5": "Northern & Western Europe",
      "id6": "2021",
      "id7": "Wikimedia España",
      "id": "id41"
   },
   {
      "id1": "Verificaton en Wikipedia / Verific-a-thon on Wikipedia",
      "id2": "This is a training event that promotes a fact-checking culture among the Wikipedian community, the I Wikipedia Verific-a-thon. It is a meeting focused on the verification of knowledge related to health issues and, specifically, to the information on COVID-19 found in the free encyclopedia.",
      "id3": "Spanish",
      "id4": "Spain",
      "id5": "Northern & Western Europe",
      "id6": "2021",
      "id7": "Wikimedia España",
      "id": "id42"
   },
   {
      "id1": "Covid-19 et désinformacion / COVID-19 and disinformation",
      "id2": "This is a research project on COVID-19 disinformation on Wikipedia.",
      "id3": "French",
      "id4": "France",
      "id5": "Northern & Western Europe",
      "id6": "2020",
      "id7": "Wikimedia France",
      "id": "id43"
   },
   {
      "id1": "Observatoire de sources / Sources observatory",
      "id2": "This is a list of reliable and unreliable sources to use on French Wikipedia.",
      "id3": "French",
      "id4": "France",
      "id5": "Northern & Western Europe",
      "id6": "2020",
      "id7": "Wikimedia France",
      "id": "id44"
   },
   {
      "id1": "Project:Sources",
      "id2": "This is a WikiProject dedicated to improving the reliability of Wikipedia articles. The volunteers working on this project ensure that articles are supported by reliable sources, answer inquiries on the reliable sources noticeboard, and maintain a list of frequently discussed sources. This project works to achieve the goals of the verifiability and no original research policies. For more information about the reliability of sources at Wikipedia, please visit our FAQ.",
      "id3": "French",
      "id4": "France",
      "id5": "Northern & Western Europe",
      "id6": "2011",
      "id7": "Wikimedia France",
      "id": "id45"
   },
   {
      "id1": "Wikimedia en Chine / Wikimedia in China",
      "id2": "This is a translation and comment for the French community of a memo released by the Wikimedia Foundation relative to an incident in the Chinese community.",
      "id3": "French",
      "id4": "France",
      "id5": "Northern & Western Europe",
      "id6": "2020",
      "id7": "Wikimedia France",
      "id": "id46"
   },
   {
      "id1": "International Science Council and Wikimedia Foundation webinar series: Exploring the opportunities and challenges of Wikipedia for science",
      "id2": "The Wikimedia Foundation organized a series of webinars in collaboration with the International Science Council, in order to explain the Wikimedia model and how it contributes to creating trustworthy information. The first webinar, Webinar 1: Managing Knowledge Integrity on Information Platforms was on March 16, 2023 and discussed how Wikipedia is a model to model for safeguard the provenance of scientific information online. Speakers were Diego Sáez Trumper (Wikimedia Foundation), Connie Moon Sheat (Hacks/Hackers), and Amalia Toledo (Wikimedia Foundation). The second webinar, Webinar 2: Building Special Projects on Wikipedia: The Covid Case Study, was on March 30, 2023 and showcased the work of the community, and in particular on the COVID-19 pandemic. The speaker was Netha Hussain, a volunteer who created the WikiProject COVID-19.",
      "id3": "English",
      "id4": "United Kingdom",
      "id5": "Northern & Western Europe",
      "id6": "2023",
      "id7": "Wikimedia Foundation",
      "id": "id47"
   },
   {
      "id1": "Wikimedia and Democracy – The impact of Wikimedia UK's information literacy work on citizen engagement",
      "id2": "This is a comprehensive analysis, by Wikimedia UK, of its programs and their impact. In Particular, they analyze the impact of their information literacy work, and how the Wikimedia movement contributes to creating a healthier information environment and stronger democracy.",
      "id3": "English",
      "id4": "United Kingdom",
      "id5": "Northern & Western Europe",
      "id6": "2021",
      "id7": "Suppose algorithm A has time complexity TA(n) = Θ(n) and algorithm B has time complexity TB(n) = Θ(n 2 ). (a) Which algorithm is generally accepted as “faster” and why?",
      "id": "id48"
   },
   {
      "id1": "Wikimedia in Education",
      "id2": "This is a booklet created by Wikimedia UK in collaboration with the University of Edinburgh about a series of case studies illustrating how to use Wikipedia as a tool for education and support learners to understand, navigate and critically evaluate information as well as develop an appreciation for the role and importance of open education.",
      "id3": "English",
      "id4": "United Kingdom",
      "id5": "Northern & Western Europe",
      "id6": "2020",
      "id7": "Wikimedia UK",
      "id": "id49"
   },
   {
      "id1": "Wikipedia:Trovärdiga källor / Wikipedia:Credible sources",
      "id2": "This is an essay explaining how to find and use credible sources in general and in particular in the Swedish language. Many Swedish-speaking Wikipedians have been involved in creating and maintaining this resource.",
      "id3": "Swedish",
      "id4": "NA",
      "id5": "Northern & Western Europe",
      "id6": "2008",
      "id7": "NA",
      "id": "id50"
   },
   {
      "id1": "Citation Hunt",
      "id2": "Citation Hunt is a tool for browsing snippets of Wikipedia articles that lack citations. It is available in several languages and allows browsing snippets either randomly or by their article's categories in a quick and fun way.[2]",
      "id3": "English",
      "id4": "NA",
      "id5": "NA",
      "id6": "2017",
      "id7": "NA",
      "id": "id51"
   },
   {
      "id1": "CiteWatch",
      "id2": "This is a bot that compiles lists of unreliable sources which are cited by Wikipedians via a specific citation template, based on several lists of unreliable or questionable publications (such as those compiled by Jeffrey Beall, the University Grants Commission, Quackwatch, or Wikipedia editors.[4]",
      "id3": "English",
      "id4": "NA",
      "id5": "NA",
      "id6": "2018",
      "id7": "NA",
      "id": "id52"
   },
   {
      "id1": "Flagged_Revisions",
      "id2": "FlaggedRevs (Flagged Revisions) is an extension of MediaWiki software that allows one to flag versions of articles and thus give additional information about quality. This comes with the possibility of changing what an unregistered user sees by default. The technical description can be found at mw:Extension:FlaggedRevs. This makes it easier to increase the article quality and trustworthiness.",
      "id3": "All",
      "id4": "NA",
      "id5": "NA",
      "id6": "2014/2017 (A 2017 moratorium established that no new Wikis can be added but those that were already active can maintain it)",
      "id7": "NA",
      "id": "id53"
   },
   {
      "id1": "masz - Media Wiki",
      "id2": "masz (the z is silent) is a tool that helps Checkusers (a small group of WP users who work on spotting fake accounts), see similarity of style and language in talk pages to find users with multiple accounts.[7]",
      "id3": "NA",
      "id4": "NA",
      "id5": "NA",
      "id6": "2021",
      "id7": "Wikimedia Foundation",
      "id": "id54"
   },
   {
      "id1": "Moderator Tools",
      "id2": "The Moderator Tools team is a Wikimedia Foundation product team working on content moderation tool needs.",
      "id3": "All",
      "id4": "NA",
      "id5": "NA",
      "id6": "2021-",
      "id7": "Wikimedia Foundation",
      "id": "id55"
   },
   {
      "id1": "New Page Patrol Source Guide",
      "id2": "This page centralizes information about reliable sources for new page reviewers to use when they review new articles. It is intended as a supplement to the reliable sources noticeboard and List of Perennial Sources, to help page reviewers unfamiliar with a given subject assess notability and neutrality of an article.[9]",
      "id3": "English",
      "id4": "NA",
      "id5": "NA",
      "id6": "2019",
      "id7": "NA",
      "id": "id56"
   },
   {
      "id1": "Template CiteQ",
      "id2": "This template returns a formatted citation from statements stored on a Wikidata item (referred to by its Q identifier or QID) describing a citable source such as a scholarly article. This project allows easy identification of citations to papers which have been redacted or replaced.[14]",
      "id3": "English",
      "id4": "NA",
      "id5": "NA",
      "id6": "2017",
      "id7": "NA",
      "id": "id57"
   },
   {
      "id1": "Vanity and Predatory Publishing",
      "id2": "This page describes vanity and predatory publishers, with links to lists of both and an explanation of why they might be dangerous for Wikipedia articles. Vanity publishers refer to publishing houses where anyone can pay to have a book published. In contrast, predatory publishers refer to an exploitative academic publishing business model that charges publication fees without checking articles' quality or providing editorial services.[16]",
      "id3": "English",
      "id4": "NA",
      "id5": "NA",
      "id6": "2017",
      "id7": "NA",
      "id": "id58"
   },
   {
      "id1": "Wikipedia Huggle",
      "id2": "Huggle is a browser intended for dealing with vandalism and other unconstructive edits on Wikimedia projects. Huggle can load and review edits made to Wikipedia in real time, it also helps users identify unconstructive edits and allows them to be reverted quickly.",
      "id3": "Spanish, French, Portuguese, English, Chinese, Dutch, Bulgarian, Russian, Serbian, Ukrainian, Azerbaijani, Bosnian, Catalan, Danish, German, Estonian, Croatian, Latvian, Norwegian, Polish, Romanian, Serbo-Croatian, Swedish, Turkish, Czech, Georgian, Urdu, Arabic, Persian, Kurdish, Hebrew, Japanese, Korean, Hindi, Bangla, Odia, Khmer, Vietnamese, Indonesian",
      "id4": "NA",
      "id5": "NA",
      "id6": "2008",
      "id7": "NA",
      "id": "id59"
   },
   {
      "id1": "Wikipedia:Deprecated sources",
      "id2": "This is a list of sources that are \"deprecated,\" whose use on Wikipedia is discouraged because they \"fail the reliable sources guidelines in nearly all circumstances.\"[19]",
      "id3": "English, Russian, Polish",
      "id4": "NA",
      "id5": "NA",
      "id6": "2018",
      "id7": "NA",
      "id": "id60"
   },
   {
      "id1": "Wikipedia:Reliable sources/Perennial sources",
      "id2": "This is a non-exhaustive list of sources whose reliability and use on Wikipedia are frequently discussed. This list summarizes prior consensus and consolidates links to the most in-depth and recent discussions from the reliable sources noticeboard and elsewhere on Wikipedia.[21]",
      "id3": "English",
      "id4": "NA",
      "id5": "NA",
      "id6": "2018",
      "id7": "NA",
      "id": "id61"
   },
   {
      "id1": "Wikipedia:Vaccine safety/Reliable sources",
      "id2": "Launched in April 2022 as a NewsQ project, Wikipedia “Reliable Sources” seeks to support Wikipedians who write articles on vaccines and want to cite reliable sources of vaccine information. NewsQ is collaborating with experienced Wikipedia editors to gather data on source quality and refine a list of reputable sources of vaccine information throughout 2023. NewsQ is a Hacks/Hackers initiative that has sought to elevate quality journalism when algorithms rank and recommend news online.",
      "id3": "English",
      "id4": "NA",
      "id5": "NA",
      "id6": "2022",
      "id7": "News Quality Initiative (NewsQ), Hacks/Hackers, and Knowledge Futures Group.For more information, read footnote [2].",
      "id": "id62"
   },
   {
      "id1": "Wikipedia:WikiProject_Reliability",
      "id2": "This is a WikiProject dedicated to improving the reliability of Wikipedia articles. This includes curating reliable sources, answer inquiries on the reliable sources noticeboard, and maintain a list of frequently discussed sources.[24]",
      "id3": "English",
      "id4": "NA",
      "id5": "NA",
      "id6": "2011",
      "id7": "NA",
      "id": "id63"
   },
   {
      "id1": "Wikipedia Knowledge Integrity Risk Observatory, Wikimedia Research",
      "id2": "Monitoring system that allows exploring data and metrics on knowledge integrity risks to compare Wikipedia language editions. Knowledge integrity risks are captured through the volume of high-risk revisions, identified with the language-agnostic revert risk machine learning (ML) model, and their revert ratios over time and across pages.",
      "id3": "English",
      "id4": "NA",
      "id5": "Global",
      "id6": "2021-",
      "id7": "Wikimedia Foundation",
      "id": "id64"
   }
]